for (i in 1:nrow(X)) {
x <- X[i, ]
# Use Kendall's tau from the Kendall package
tau_value <- Kendall(x, y)$tau
# Update maximum tau
if (tau_value > max_tau) {
max_tau <- tau_value
}
}
return(max_tau)
}
set.seed(123) # For reproducibility
X <- matrix(sample(1:100, 100 * 100, replace = TRUE), nrow = 100, ncol = 100)
# Measure the running time using system.time
start_time <- Sys.time()
result <- matrix_kendall(X)
end_time <- Sys.time()
# Calculate the time taken in seconds
time_taken <- end_time - start_time
# Print the result and time taken
print(result)
print(paste("Time taken: ", time_taken, " seconds"))
library(Kendall)
matrix_kendall <- function(X) {
n <- ncol(X)
y <- 1:n
max_tau <- -Inf
for (i in 1:nrow(X)) {
x <- X[i, ]
# Use Kendall's tau from the Kendall package
tau_value <- Kendall(x, y)$tau
# Update maximum tau
if (tau_value > max_tau) {
max_tau <- tau_value
}
}
return(max_tau)
}
set.seed(123) # For reproducibility
X <- matrix(sample(1:1000, 1000 * 1000, replace = TRUE), nrow = 1000, ncol = 1000)
# Measure the running time using system.time
start_time <- Sys.time()
result <- matrix_kendall(X)
end_time <- Sys.time()
# Calculate the time taken in seconds
time_taken <- end_time - start_time
# Print the result and time taken
print(result)
print(paste("Time taken: ", time_taken, " seconds"))
help(Kendall)
A<-c(2.5,2.5,2.5,2.5,5,6.5,6.5,10,10,10,10,10,14,14,14,16,17)
B<-c(1,1,1,1,2,1,1,2,1,1,1,1,1,1,2,2,2)
summary(Kendall(A,B))
help('sort')
help(order)
# Return the maximum Kendall's Tau from all rows
return(max(taus))  # Return the maximum tau value
# the algorithm looks like this:
# 1. sort x and then reorder y based on x's order
# 2. Count Inversions in y based on the merged_sort algorithm
# An inversion is a pair $(i, j)$ where $i < j$ and $y_i > y_j$ indicating a discordant pair.
# 3. Compute Kendallâ€™s Tau
# once the number of swaps $S(y)$ is computed using merge sort, the Kendall's Tau statistic can be calculated as:
# $$ \tau = 1 - \frac{2S(y)}{n(n-1)/2} $$
# This formula is derived from the total number of pairs and the number of discordant pairs.
# Repeat for All Rows and conduct the maximum of it.
# the reason to choose merge sort because the algorithm runs in O(nlog(n))
# which is faster than the bubble sort
merge_and_count_swaps <- function(left, right) {
i <- 1  # Initialize index for the left array
j <- 1  # Initialize index for the right array
n_left <- length(left)  # Get the length of the left array
n_right <- length(right)  # Get the length of the right array
total_length <- n_left + n_right  # Total length of the merged array
merged <- numeric(total_length)  # Pre-allocate memory for the merged array to avoid using `c()`
swaps <- 0  # Initialize the count of inversions (swaps)
k <- 1  # Index for filling the merged array
# While both arrays still have unmerged elements
while (i <= n_left && j <= n_right) {
# If the current element of the left array is smaller or equal, place it in the merged array
if (left[i] <= right[j]) {
merged[k] <- left[i]  # Insert the element from left array into merged
i <- i + 1  # Move to the next element in the left array
} else {
merged[k] <- right[j]  # Insert the element from right array into merged
swaps <- swaps + (n_left - i + 1)  # Count the inversions (remaining elements in left are greater than right[j])
j <- j + 1  # Move to the next element in the right array
}
k <- k + 1  # Move to the next position in the merged array
}
# If there are remaining elements in the left array, append them to the merged array
if (i <= n_left) {
merged[k:total_length] <- left[i:n_left]  # Add the remaining elements from the left array
}
# If there are remaining elements in the right array, append them to the merged array
else if (j <= n_right) {
merged[k:total_length] <- right[j:n_right]  # Add the remaining elements from the right array
}
# Return the merged array and the total number of swaps (inversions)
return(list(merged = merged, swaps = swaps))
}
# Recursive Merge Sort function to sort the array and count the number of swaps (inversions)
merge_sort_and_count_swaps <- function(arr) {
n <- length(arr)  # Get the length of the array
if (n <= 1) {
return(list(sorted = arr, swaps = 0))  # Base case: if the array has one or zero elements, it's already sorted
}
mid <- floor(n / 2)  # Find the middle index to split the array
# Recursively sort and count swaps in the left half
left_result <- merge_sort_and_count_swaps(arr[1:mid])
# Recursively sort and count swaps in the right half
right_result <- merge_sort_and_count_swaps(arr[(mid + 1):n])
# Merge the two sorted halves and count any additional swaps
merged_result <- merge_and_count_swaps(left_result$sorted, right_result$sorted)
# Total swaps are the sum of swaps in the left half, right half, and during merging
total_swaps <- left_result$swaps + right_result$swaps + merged_result$swaps
# Return the sorted array and total number of swaps
return(list(sorted = merged_result$merged, swaps = total_swaps))
}
# Function to compute Kendall's Tau between two sequences x and y using Merge Sort to count swaps
kendall_tau_sorted <- function(x, y) {
n <- length(x)  # Get the length of the sequences
# Sort x and apply the same permutation to y
ord <- order(x)  # Get the order (indices) to sort x
y_sorted <- y[ord]  # Apply the same order to y to align with sorted x
# Use merge sort to count the swaps (inversions) in y_sorted
result <- merge_sort_and_count_swaps(y_sorted)
# Precompute the total number of possible pairs (n choose 2) for Tau calculation
total_pairs <- n * (n - 1) / 2  # This is the number of possible pairwise comparisons
# Compute Kendall's Tau using the number of swaps
swaps <- result$swaps  # Get the number of swaps from the result
tau <- 1 - (2 * swaps / total_pairs)  # Formula for Kendall's Tau: 1 - 2 * (swaps / total pairs)
return(tau)  # Return the Kendall's Tau value
}
# Main function to compute the maximum Kendall's Tau across all rows of matrix X
matrix_kendall <- function(X) {
m <- nrow(X)  # Get the number of rows in matrix X
n <- ncol(X)  # Get the number of columns in matrix X
y <- 1:n  # Create a reference sequence y = (1, 2, ..., n)
# Apply kendall_tau_sorted to each row of matrix X and store the results in taus
taus <- apply(X, 1, function(row) kendall_tau_sorted(row, y))  # Apply the function to each row
# Return the maximum Kendall's Tau from all rows
return(max(taus))  # Return the maximum tau value
}
set.seed(123) # For reproducibility
X <- t(sapply(1:1200, function(i) sample(1:1200, 1200, replace = FALSE)))
matrix_kendall( matrix ( c (1 , 2 , 2 , 1) , 2 , 2))
matrix_kendall ( matrix ( c (2 , 2 , 1 , 1) , 2 , 2))
# Measure the running time using system.time
start_time <- Sys.time()
result <- matrix_kendall(X)
end_time <- Sys.time()
# Calculate the time taken in seconds
time_taken <- end_time - start_time
# Print the result and time taken
print(result)
print(paste("Time taken: ", time_taken, " seconds"))
merge_and_count_swaps <- function(left, right) {
i <- 1
j <- 1
merged <- c()
swaps <- 0
n_left <- length(left)
n_right <- length(right)
# Merge process with swap counting
while (i <= n_left && j <= n_right) {
if (left[i] <= right[j]) {
merged <- c(merged, left[i])
i <- i + 1
} else {
merged <- c(merged, right[j])
swaps <- swaps + (n_left - i + 1)  # Count inversions (swaps)
j <- j + 1
}
}
# Append remaining elements
if (i <= n_left) {
merged <- c(merged, left[i:n_left])
}
if (j <= n_right) {
merged <- c(merged, right[j:n_right])
}
return(list(merged = merged, swaps = swaps))
}
# Recursive Merge Sort function to sort and count swaps (inversions)
merge_sort_and_count_swaps <- function(arr) {
n <- length(arr)
if (n <= 1) {
return(list(sorted = arr, swaps = 0))
}
mid <- floor(n / 2)
left_result <- merge_sort_and_count_swaps(arr[1:mid])
right_result <- merge_sort_and_count_swaps(arr[(mid + 1):n])
merged_result <- merge_and_count_swaps(left_result$sorted, right_result$sorted)
total_swaps <- left_result$swaps + right_result$swaps + merged_result$swaps
return(list(sorted = merged_result$merged, swaps = total_swaps))
}
# Function to compute Kendall's Tau using Merge Sort for counting swaps
kendall_tau_sorted <- function(x, y) {
n <- length(x)
# Sort x and apply the same permutation to y
ord <- order(x)
y_sorted <- y[ord]
# Use merge sort to count the swaps in y_sorted
result <- merge_sort_and_count_swaps(y_sorted)
# Compute tau using the swap count
swaps <- result$swaps
tau <- 1 - (2 * swaps / (n * (n - 1) / 2))
return(tau)
}
# Main function to compute maximum Kendall's Tau across all rows
matrix_kendall <- function(X) {
m <- nrow(X)
n <- ncol(X)
y <- 1:n  # Sequence y = (1, 2, ..., n)
max_tau <- -Inf
for (i in 1:m) {
current_tau <- kendall_tau_sorted(X[i, ], y)
if (current_tau > max_tau) {
max_tau <- current_tau
}
}
return(max_tau)
}
matrix_kendall( matrix ( c (1 , 2 , 2 , 1) , 2 , 2))
matrix_kendall ( matrix ( c (2 , 2 , 1 , 1) , 2 , 2))
# Measure the running time using system.time
start_time <- Sys.time()
result <- matrix_kendall(X)
end_time <- Sys.time()
# Calculate the time taken in seconds
time_taken <- end_time - start_time
# Print the result and time taken
print(result)
print(paste("Time taken: ", time_taken, " seconds"))
help("data.frame")
x <- 0.54
print(x)
print(.45)
print(84 213)
x <- 984x
x <- 1+2i
print(x)
x <- 90L
print(x)
x <- as.raw(50)
print(x)
x <- 1 + 2i
x <- 1+3i
print(x)
x <- 1 + 2i
print(x)
x <- 0+2i
print(x)
x<-2i
print(x)
x<-0-2i
print(x)
help(outer)
help(combn)
exit
help(dist)
help(all)
help(data.table)
help(table)
help(which)
exists()
library(bigrquery) # used for querying BigQuery
library(ggplot2) # used for visualization
library(dplyr) # used for data wrangling
library(caret)  # For data splitting and evaluation
library(Metrics)  # For RMSE calculation
library(DBI)
bq_auth()
# natality_data
csv_file_path <- "natality_data.csv" # Specify the file name and path
data <- read.csv(csv_file_path)
setwd("/home/xuyuan/Desktop/2024 fall/project_data/original_data")
# now we can generate the edges
output_directory <- gsub("original_data", "cleaned", current_dir)
cleaning_dir <- merge_hic_with_alu(data_dir, output_directory)
current_dir <- getwd()
# now we can generate the edges
output_directory <- gsub("original_data", "cleaned", current_dir)
cleaning_dir <- merge_hic_with_alu(data_dir, output_directory)
dataframe <- read.csv(paste0(output_directory, '/', "edges_data_frame.csv"))
dataframe$group <- NULL
# now we consider the group of the data by using the Leiden algorithm
# we first start using the chromosome 21
data <- dataframe[which(dataframe$chromosome == "chr21"), ]
gdf <- graph_from_data_frame(data, directed = FALSE)
library(igraph)
gdf <- graph_from_data_frame(data, directed = FALSE)
View(gdf)
View(dataframe)
View(data)
gdf <- graph_from_data_frame(data, directed = FALSE)
print(ecount(gdf))
# now we consider the group of the data by using the Leiden algorithm
# we first start using the chromosome 21
data <- dataframe[which(dataframe$chromosome == "chr1"), ]
runIgraph <- function(gdf, iterations, gamma, theta) {
ldc <- cluster_leiden(
gdf,
resolution = gamma,  # Correct argument
objective_function = "CPM",
weights = E(gdf)$weight,  # Use edge weights from the graph
beta = theta,
n_iterations = iterations,
vertex_weights = rep(1, vcount(gdf))  # Use vertex count from the graph
)
return(ldc)
}
library(igraph)
gdf <- graph_from_data_frame(data, directed = FALSE)
E(gdf)$weight <- as.numeric(data$node_weights)
set.seed(1)
result <- runIgraph(gdf, 50, 0.0005, 0.0001)
print(length(unique(result$membership)))
result <- runIgraph(gdf, 50, 0.00005, 0.0001)
print(length(unique(result$membership)))
result <- runIgraph(gdf, 50, 0.0005, 0.0001)
print(length(unique(result$membership)))
# we can now plot the graph
# Match data to graph nodes
matched_data <- data[match(V(gdf)$name, data$X), ]
# Assign the dominant family or "Other" if counts are equal
matched_data$dominant_family <- apply(
matched_data[, c("AluJ_count", "AluS_count", "AluY_count")],
1,
function(row) {
if (length(unique(row[!is.na(row)])) == 1 || all(is.na(row)) || all(row == 0)) {
return(4)  # Assign to "Other" if all counts are equal
} else {
return(which.max(row))  # Assign to the max family otherwise
}
}
)
matched_data$dominant_family <- as.numeric(matched_data$dominant_family)
# Add the dominant family to the graph
V(gdf)$alu_family <- factor(
matched_data$dominant_family,
levels = 1:4,
labels = c("AluJ", "AluS", "AluY", "Other")
)
print(unique(V(gdf)$alu_family))
plotLeiden <- function(result, gdf, Alus = FALSE) {
# Ensure gdf is an igraph object
if (!inherits(gdf, "igraph")) {
stop("Input `gdf` must be an igraph object.")
}
# Assign community memberships to nodes in the graph
V(gdf)$membership <- result$membership
# Normalize edge weights for better visualization
if (!is.null(E(gdf)$weight)) {
E(gdf)$scaled_weight <- scales::rescale(E(gdf)$weight, to = c(1, 15))
} else {
E(gdf)$scaled_weight <- rep(1, ecount(gdf))  # Default weight if none exists
}
# Create colormap for the communities
num_communities <- length(unique(result$membership))
community_colors <- rainbow(num_communities)
colors <- community_colors[as.factor(V(gdf)$membership)]
# Ensure alu_family attribute exists in the graph
if (!"alu_family" %in% vertex_attr_names(gdf)) {
stop("The graph does not contain the 'alu_family' attribute. Please assign it before plotting.")
}
# Map Alu families to colors
alu_family_colors <- c("red", "blue", "green", "purple")  # Assign specific colors to AluJ, AluS, AluY
alu_family_labels <- c("AluJ", "AluS", "AluY", "Other")
alu_colors <- alu_family_colors[V(gdf)$alu_family]
# Plot logic
plot_ <- function() {
plot(
gdf,
layout = layout_with_fr(gdf),
vertex.color = alu_colors,  # Use Alu family colors
vertex.size = 4,
vertex.frame.color = alu_colors,
edge.color = "grey",  # Default edge color
edge.width = E(gdf)$scaled_weight,  # Use scaled weights
vertex.label = NA,  # Suppress labels
edge.arrow.size = 0,
main = ifelse(Alus, "Candidate Chromatin Modulating Alu Communities (Chr22)", "Our Rcpp-based Clustering")
)
if (!Alus) {
legend("topright", legend = alu_family_labels,
col = alu_family_colors, pch = 19,
title = "Alu Families", cex = 0.8)
} else {
# Add a legend to the top-right
legend(
"topright",
legend = alu_family_labels,
col = alu_family_colors,
pch = 19,
title = "Alu Families",
cex = 0.8
)
}
}
# Save the plot to a PNG file with 300 DPI
png("alu_plot.png", width = 2000, height = 2000, res = 300)
plot_()
dev.off()
}
plotLeiden(result, gdf, Alus = TRUE)
# now we consider the group of the data by using the Leiden algorithm
# we first start using the chromosome 21
data <- dataframe[which(dataframe$chromosome == "chr21"), ]
runIgraph <- function(gdf, iterations, gamma, theta) {
ldc <- cluster_leiden(
gdf,
resolution = gamma,  # Correct argument
objective_function = "CPM",
weights = E(gdf)$weight,  # Use edge weights from the graph
beta = theta,
n_iterations = iterations,
vertex_weights = rep(1, vcount(gdf))  # Use vertex count from the graph
)
return(ldc)
}
library(igraph)
gdf <- graph_from_data_frame(data, directed = FALSE)
E(gdf)$weight <- as.numeric(data$node_weights)
set.seed(1)
result <- runIgraph(gdf, 50, 0.0005, 0.0001)
print(length(unique(result$membership)))
# we can now plot the graph
# Match data to graph nodes
matched_data <- data[match(V(gdf)$name, data$X), ]
# Assign the dominant family or "Other" if counts are equal
matched_data$dominant_family <- apply(
matched_data[, c("AluJ_count", "AluS_count", "AluY_count")],
1,
function(row) {
if (length(unique(row[!is.na(row)])) == 1 || all(is.na(row)) || all(row == 0)) {
return(4)  # Assign to "Other" if all counts are equal
} else {
return(which.max(row))  # Assign to the max family otherwise
}
}
)
matched_data$dominant_family <- as.numeric(matched_data$dominant_family)
# Add the dominant family to the graph
V(gdf)$alu_family <- factor(
matched_data$dominant_family,
levels = 1:4,
labels = c("AluJ", "AluS", "AluY", "Other")
)
print(unique(V(gdf)$alu_family))
plotLeiden <- function(result, gdf, Alus = FALSE) {
# Ensure gdf is an igraph object
if (!inherits(gdf, "igraph")) {
stop("Input `gdf` must be an igraph object.")
}
# Assign community memberships to nodes in the graph
V(gdf)$membership <- result$membership
# Normalize edge weights for better visualization
if (!is.null(E(gdf)$weight)) {
E(gdf)$scaled_weight <- scales::rescale(E(gdf)$weight, to = c(1, 15))
} else {
E(gdf)$scaled_weight <- rep(1, ecount(gdf))  # Default weight if none exists
}
# Create colormap for the communities
num_communities <- length(unique(result$membership))
community_colors <- rainbow(num_communities)
colors <- community_colors[as.factor(V(gdf)$membership)]
# Ensure alu_family attribute exists in the graph
if (!"alu_family" %in% vertex_attr_names(gdf)) {
stop("The graph does not contain the 'alu_family' attribute. Please assign it before plotting.")
}
# Map Alu families to colors
alu_family_colors <- c("red", "blue", "green", "purple")  # Assign specific colors to AluJ, AluS, AluY
alu_family_labels <- c("AluJ", "AluS", "AluY", "Other")
alu_colors <- alu_family_colors[V(gdf)$alu_family]
# Plot logic
plot_ <- function() {
plot(
gdf,
layout = layout_with_fr(gdf),
vertex.color = alu_colors,  # Use Alu family colors
vertex.size = 4,
vertex.frame.color = alu_colors,
edge.color = "grey",  # Default edge color
edge.width = E(gdf)$scaled_weight,  # Use scaled weights
vertex.label = NA,  # Suppress labels
edge.arrow.size = 0,
main = ifelse(Alus, "Candidate Chromatin Modulating Alu Communities (Chr22)", "Our Rcpp-based Clustering")
)
if (!Alus) {
legend("topright", legend = alu_family_labels,
col = alu_family_colors, pch = 19,
title = "Alu Families", cex = 0.8)
} else {
# Add a legend to the top-right
legend(
"topright",
legend = alu_family_labels,
col = alu_family_colors,
pch = 19,
title = "Alu Families",
cex = 0.8
)
}
}
# Save the plot to a PNG file with 300 DPI
png("alu_plot.png", width = 2000, height = 2000, res = 300)
plot_()
dev.off()
}
plotLeiden(result, gdf, Alus = TRUE)
